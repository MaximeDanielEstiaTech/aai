{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bafe8f6",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation (RAG)\n",
    "\n",
    "RAG enhances an LLM by retrieving relevant documents (external data) before generating a response. This allows the model to ground its answers in factual information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6cf14ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing daniel2018cairnform.pdf...\n",
      "Processing doudna2014crispr.pdf...\n",
      "Creating Chroma database...\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "# Initialize Ollama embeddings\n",
    "ollama_embeddings = OllamaEmbeddings(model=\"qwen3:4b\")\n",
    "\n",
    "persist_directory=\"db/\"\n",
    "pdf_folder_path = \"files/\"\n",
    "\n",
    "all_chunks = []\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "\n",
    "for fn in os.listdir(pdf_folder_path):\n",
    "    if not fn.endswith(\".pdf\"):\n",
    "        continue\n",
    "    print(f\"Processing {fn}...\")\n",
    "    path_file = os.path.join(pdf_folder_path, fn)\n",
    "\n",
    "    # Load the PDF document\n",
    "    loader = PyPDFLoader(path_file)\n",
    "    documents = loader.load()\n",
    "\n",
    "    # Split the documents into smaller chunks for better retrieval\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    all_chunks.extend(chunks)\n",
    "\n",
    "# Create a Chroma database from the document chunks\n",
    "\n",
    "print(\"Creating Chroma database...\")\n",
    "\n",
    "db = Chroma.from_documents(all_chunks, embedding=ollama_embeddings, persist_directory = persist_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4493458b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search results:\n",
      "\n",
      "\n",
      "shared practices by displaying energy data in collective and\n",
      "public spaces, such as public places and workplaces. It is 360˚-\n",
      "readable, and as a dynamic physical ring chart, it can change\n",
      "its cylindrical symmetry with quiet motion. W e conducted two\n",
      "user studies. The ﬁrst study clearly revealed the attractiveness\n",
      "of CairnFORM in a public place and its usability for a range\n",
      "task and for a compare task. Consequently , this makes\n",
      "CairnFORM useful to analyze renewable energy availability .\n",
      "\n",
      "\n",
      "emmanuelle.charpentier@helmholtz-hzi.de (E.C.)\n",
      "\n",
      "\n",
      "the two following exercises. These two exercises aim at\n",
      "catching the ring’s motion with the peripheral vision, but with\n",
      "different attention levels: one is with the focus of attention\n",
      "(i.e., focusing attention on the detection task) and the other\n",
      "7 The mid-peripheral vision—covering the region from 30˚ to 60˚—\n",
      "deﬁnes the limit of the upwards peripheral vision [13].\n",
      "8 Repeated measures with three apps on a smartphone and a tablet.\n",
      "\n",
      "\n",
      "88-cm-diameter, spherical screen is designed to inform in\n",
      "stadiums. StaTube [15] is a 360˚-display designed for ofﬁces:\n",
      "it displays user states with seven illuminated rings of 6 cm\n",
      "diameter and it is 17 cm high. V essels of Irelands Past 4 is an\n",
      "example of 360˚-readable chart that is, however, not a dynamic\n",
      "chart. The skeleton of Amphorm [32] is a 33-cm-high tower\n",
      "of ﬁve expandable rings that, however, was not designed to\n",
      "display ordinal data and morphs to an 11-point star shape.\n"
     ]
    }
   ],
   "source": [
    "PROMPT0 = \"What is the CairnFORM prototype?\"\n",
    "results = db.similarity_search(PROMPT0)\n",
    "print(\"Search results:\")\n",
    "for result in results:\n",
    "    print(f\"\\n\\n{result.page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab62570f",
   "metadata": {},
   "source": [
    "# Define Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9475d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_BASE_URL = \"http://localhost:11434\"\n",
    "LLM_MODEL = \"qwen3:4b\"\n",
    "LLM_SEED = 42 \n",
    "LLM_TEMPERATURE = 0.0\n",
    "TEST_PROMPT0 = \"What time is it?\"\n",
    "TEST_PROMPT1 = \"What is the price of gold right now?\"\n",
    "TEST_PROMPT3 = \"How many 1 in 111111111111111?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadad677",
   "metadata": {},
   "source": [
    "# Initialize Ollama Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61fa1adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# minimize randomness for reproducibility\n",
    "seed = 42\n",
    "temperature = 0\n",
    "\n",
    "# Set up the Ollama chat model with specified LLM model and parameters\n",
    "llm = ChatOllama(\n",
    "    base_url=OLLAMA_BASE_URL,\n",
    "    model=LLM_MODEL,\n",
    "    temperature=LLM_TEMPERATURE,\n",
    "    seed=LLM_SEED,\n",
    "    stream=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53c17529",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def retrieve(query: str):\n",
    "    \"\"\"Retrieve information related to a query.\"\"\"\n",
    "    retrieved_docs = db.similarity_search(query, k=2)\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\n\" f\"Content: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized\n",
    "\n",
    "tools = [retrieve]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1b4d919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following questions as best you can.\n",
      "You can answer directly if the user is greeting you or similar.\n",
      "Otherwise, you have access to the following tools:\n",
      "\n",
      "retrieve(query: str) - Retrieve information related to a query.\n",
      "\n",
      "The way you use the tools is by specifying a json blob.\n",
      "Specifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\n",
      "\n",
      "The only values that should be in the \"action\" field are: retrieve\n",
      "\n",
      "The $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"action\": $TOOL_NAME,\n",
      "  \"action_input\": $INPUT\n",
      "}\n",
      "```\n",
      "\n",
      "ALWAYS use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action:\n",
      "```\n",
      "$JSON_BLOB\n",
      "```\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin! Reminder to always use the exact characters `Final Answer:` when responding.\n",
      "Always make your final answer easy to read and understand for humans.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "from inspect import signature\n",
    "\n",
    "tools_names = \", \".join([tool.name for tool in tools])\n",
    "tools_descriptions = \"\\n\".join([f\"{tool.name}{signature(tool.func)} - {tool.description}\" for tool in tools]) \n",
    "\n",
    "\n",
    "# Taken from https://smith.langchain.com/hub/hwchase17/react-json\n",
    "instructions = f\"\"\"Answer the following questions as best you can.\n",
    "You can answer directly if the user is greeting you or similar.\n",
    "Otherwise, you have access to the following tools:\n",
    "\n",
    "{tools_descriptions}\n",
    "\n",
    "The way you use the tools is by specifying a json blob.\n",
    "Specifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\n",
    "\n",
    "The only values that should be in the \"action\" field are: {tools_names}\n",
    "\n",
    "The $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\n",
    "\n",
    "```\n",
    "{{\n",
    "  \"action\": $TOOL_NAME,\n",
    "  \"action_input\": $INPUT\n",
    "}}\n",
    "```\n",
    "\n",
    "ALWAYS use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action:\n",
    "```\n",
    "$JSON_BLOB\n",
    "```\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin! Reminder to always use the exact characters `Final Answer:` when responding.\n",
    "Always make your final answer easy to read and understand for humans.\n",
    "\"\"\"\n",
    "\n",
    "print(instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0310eee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain.schema import BaseMessage, AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "class Chatbot:\n",
    "    llm: ChatOllama\n",
    "    history: List[BaseMessage]\n",
    "\n",
    "    def __init__(self, llm: ChatOllama, history: List[BaseMessage] = []):\n",
    "        \"\"\"Initialize the chatbot with an LLM and an optional history.\"\"\"\n",
    "        self.llm = llm\n",
    "        self.history = history\n",
    "    \n",
    "    def invoke(self, prompt:str) -> None:\n",
    "        \"\"\"Run the chatbot with the current history.\"\"\"\n",
    "        clear_output(wait=True)\n",
    "        self.pretty_print()\n",
    "        human_message = HumanMessage(content=prompt)\n",
    "        human_message.pretty_print()\n",
    "        self.history.append(human_message)\n",
    "        ai_message = AIMessage(content=\"\")\n",
    "        ai_message.pretty_print()\n",
    "        print()\n",
    "        for chunk in self.llm.stream(self.history):\n",
    "            print(chunk.content, end=\"\")\n",
    "            ai_message.content += chunk.content\n",
    "        print()\n",
    "        self.history.append(ai_message)\n",
    "        \n",
    "    \n",
    "    def interact(self) -> None:\n",
    "        \"\"\"Run the chatbot in interactive mode.\"\"\"\n",
    "        while True: \n",
    "            prompt = input(\"Prompt (Enter 'stop' to exit)\")\n",
    "            if prompt == \"stop\": \n",
    "                break\n",
    "            self.invoke(prompt)\n",
    "\n",
    "\n",
    "    def pretty_print(self) -> None:\n",
    "        \"\"\"Pretty print the chatbot's history.\"\"\"\n",
    "        for message in self.history:\n",
    "            message.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5800d72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import BaseMessage, AIMessage, HumanMessage, SystemMessage\n",
    "import re\n",
    "from typing import Union\n",
    "from langchain_core.agents import AgentAction, AgentFinish, AgentActionMessageLog\n",
    "from langchain_core.exceptions import OutputParserException\n",
    "from langchain.agents.agent import AgentOutputParser\n",
    "from langchain.agents.chat.prompt import FORMAT_INSTRUCTIONS\n",
    "import ast\n",
    "from IPython.display import clear_output, display\n",
    "from langchain_core.messages import ToolMessage\n",
    "import traceback\n",
    "import sys\n",
    "from ollama import Tool\n",
    "\n",
    "class Agent(Chatbot):\n",
    "\n",
    "    tools: List[Tool]\n",
    "    \n",
    "    def __init__(self, llm: ChatOllama, tools: List[Tool], history: List[BaseMessage] = []):\n",
    "        \"\"\"Initialize the chatbot with an LLM, tools, and an optional history.\"\"\"\n",
    "        super().__init__(llm, history)\n",
    "        self.tools = tools\n",
    "\n",
    "    def invoke(self, prompt:str) -> None:\n",
    "        \"\"\"Run the chatbot in interactive mode.\"\"\"\n",
    "        self.history.append(HumanMessage(content=prompt))\n",
    "        clear_output(wait=True)\n",
    "        self.pretty_print()\n",
    "        stop = False\n",
    "        while not stop:\n",
    "            ai_pre_action_message = self.llm.invoke(self.history)\n",
    "            self.history.append(ai_pre_action_message)\n",
    "            try:\n",
    "                action = self.parse_action(ai_pre_action_message.content)\n",
    "                if isinstance(action, AgentAction):\n",
    "                    tool_message = self.call_tool(action)\n",
    "                    self.history.append(tool_message)\n",
    "                if isinstance(action, AgentFinish):\n",
    "                    stop = True\n",
    "            except SyntaxError as e:\n",
    "                self.history.append(SystemMessage(content=str(e)))\n",
    "            except Exception as e:\n",
    "                traceback.print_exc()\n",
    "                sys.exit()\n",
    "            clear_output(wait=True)\n",
    "            self.pretty_print()\n",
    "\n",
    "\n",
    "    def call_tool(self, action: AgentAction) -> ToolMessage:\n",
    "        \"\"\"Call the specified tool with the given action input.\"\"\"\n",
    "        tool = next((t for t in self.tools if t.name == action.tool), None)\n",
    "        if not tool:\n",
    "            return ToolMessage(content=f\"Error: Tool '{action.tool}' does not exist.\", tool_call_id=\"unknown_tool\")\n",
    "        result = None\n",
    "        sig = signature(tool.func)\n",
    "        if len(sig.parameters):\n",
    "            action_input = action.tool_input\n",
    "            if not isinstance(action_input, dict):\n",
    "                param_name = next(iter(sig.parameters))\n",
    "                action_input = {param_name: action_input}\n",
    "            result = tool.func(**action_input)\n",
    "        else:\n",
    "            result = tool.func()\n",
    "        return ToolMessage(content=f\"{result}\", tool_call_id=tool.func.__name__)\n",
    "    \n",
    "    \n",
    "    def parse_action(self, text:str) -> Union[AgentAction, AgentActionMessageLog, AgentFinish]:\n",
    "        \"\"\"Parse the action from the LLM output text and return an AgentAction or AgentFinish object.\"\"\"\n",
    "        FINAL_ANSWER_ACTION = \"Final Answer:\"\n",
    "        pattern = re.compile(r\"^.*?`{3}(?:json)?\\n?(.*?)`{3}.*?$\", re.DOTALL)\n",
    "        includes_answer = FINAL_ANSWER_ACTION in text\n",
    "        try:\n",
    "            found = pattern.search(text)\n",
    "            if not found:\n",
    "                raise ValueError(\"action not found.\")\n",
    "            action = found.group(1)\n",
    "            response = ast.literal_eval(action.strip())\n",
    "            return AgentAction(response[\"action\"], response.get(\"action_input\", {}), text)\n",
    "        except Exception as e:\n",
    "            if not includes_answer:\n",
    "                raise SyntaxError(\"Reminder to always use the exact characters `Final Answer:` when responding.\")\n",
    "            output = text.split(FINAL_ANSWER_ACTION)[-1].strip()\n",
    "            return AgentFinish({\"output\": output}, text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae8c3d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "Answer the following questions as best you can.\n",
      "You can answer directly if the user is greeting you or similar.\n",
      "Otherwise, you have access to the following tools:\n",
      "\n",
      "retrieve(query: str) - Retrieve information related to a query.\n",
      "\n",
      "The way you use the tools is by specifying a json blob.\n",
      "Specifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\n",
      "\n",
      "The only values that should be in the \"action\" field are: retrieve\n",
      "\n",
      "The $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"action\": $TOOL_NAME,\n",
      "  \"action_input\": $INPUT\n",
      "}\n",
      "```\n",
      "\n",
      "ALWAYS use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action:\n",
      "```\n",
      "$JSON_BLOB\n",
      "```\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin! Reminder to always use the exact characters `Final Answer:` when responding.\n",
      "Always make your final answer easy to read and understand for humans.\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the CairnFORM prototype?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<think>\n",
      "Okay, the user is asking about the CairnFORM prototype. I need to figure out what that is. First, I should check if I have any existing knowledge about it. Wait, I don't recall anything specific about CairnFORM. Maybe it's a recent development or a specialized term. Since I can't rely on my existing knowledge, I should use the retrieve tool to get information on this topic.\n",
      "\n",
      "I'll start by using the retrieve function with the query \"CairnFORM prototype\". That should fetch any relevant information from the available resources. Let me see what comes up. \n",
      "\n",
      "Hmm, the retrieval might return details about the prototype, like its purpose, features, or related projects. If the result is a description, I can summarize that. If there's no information, I'll have to inform the user that it's not available. But since the user is asking, there's likely some information out there. Let me check the retrieved data.\n",
      "</think>\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"retrieve\",\n",
      "  \"action_input\": \"CairnFORM prototype\"\n",
      "}\n",
      "```\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "Source: {'author': 'Maxime Daniel, Guillaume Rivière, Nadine Couture', 'creationdate': '2018-12-04T16:16:23+01:00', 'creator': 'LaTeX with hyperref package', 'keywords': 'Tangible User Interface; Shape-Changing Interface; Data Physicalization; Ring Chart; Renewable Energy; Demand-Side Management; Shifting Energy Demand; Ambient Notifications; Peripheral Vision; User Study.', 'moddate': '2025-06-10T05:23:34-07:00', 'page': 2, 'page_label': '3', 'producer': 'GPL Ghostscript 9.26; modified using iText 4.2.0 by 1T3XT', 'source': 'files/daniel2018cairnform.pdf', 'subject': '', 'title': 'CairnFORM: a Shape-Changing Ring Chart Notifying Renewable Energy Availability in Peripheral Locations', 'total_pages': 12}\n",
      "Content: by Sconst , Sex p , and Slog , respectively . W e applied these three\n",
      "speeds to the two kinds of ring’s motion: a full expansion,\n",
      "which increases the diameter from 35 cm to 62 cm, and a\n",
      "full retraction, which decreases the diameter from 62 cm to\n",
      "35 cm. These two motions were done in six seconds. W e\n",
      "denote these two motions in the following by\n",
      "Mex pansion and\n",
      "Mret ract ion, respectively .\n",
      "Implementation\n",
      "W e designed a prototype of CairnFORM on the basis of\n",
      "\n",
      "Source: {'creationdate': '2014-11-27T13:04:40-08:00', 'creator': 'PyPDF', 'moddate': '2014-11-27T13:04:40-08:00', 'page': 8, 'page_label': '9', 'producer': 'Adobe PDF Library 9.1', 'source': 'files/doudna2014crispr.pdf', 'total_pages': 11}\n",
      "Content: 24. A. Jacquier, B. Dujon, An intron-encoded protein is active in a\n",
      "gene conversion process that spreads an intron into a\n",
      "mitochondrial gene. Cell 41, 383– 394 (1985). doi:10.1016/\n",
      "S0092-8674(85)80011-8; pmid: 3886163\n",
      "SCIENCE sciencemag.org 28 NOVEMBER 2014 • VOL 346 ISSUE 6213 1258096-7\n",
      "Human gene therapy\n",
      "Screens for drug target ID Agriculture: crops, animals\n",
      "Ecological vector control:\n",
      "mosquito sterilization, etc.\n",
      "Viral gene disruption;\n",
      "pathogen gene disruption\n",
      "Programmable RNA targeting\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<think>\n",
      "Okay, the user asked about the CairnFORM prototype. Let me look at the retrieved information. The first source mentions a paper titled \"CairnFORM: a Shape-Changing Ring Chart Notifying Renewable Energy Availability in Peripheral Locations.\" The authors are Maxime Daniel, Guillaume Rivière, and Nadine Couture. The creation date is 2018-12-04, and the PDF is from files/daniel2018cairnform.pdf. The content talks about a prototype where the ring chart expands and retracts to notify about renewable energy availability. The implementation details include speeds for expansion and retraction, and the motions are called Mex pansion and Mret ract ion.\n",
      "\n",
      "The second source is from a PDF about CRISPR and doesn't seem relevant. So the main info is from the first source. The CairnFORM prototype is a shape-changing ring chart used to notify users about renewable energy availability in peripheral locations. It uses motions like expansion and retraction to indicate energy availability. The authors are from 2018, and the study is about tangible user interfaces and data physicalization. The final answer should summarize this, mentioning the purpose, mechanism, and context of the prototype.\n",
      "</think>\n",
      "\n",
      "Final Answer: The CairnFORM prototype is a shape-changing ring chart designed to notify users about renewable energy availability in peripheral locations. It uses physical motion—such as expansion and retraction of its diameter—to visually represent energy data. The prototype was developed as part of research on tangible user interfaces and data physicalization, aiming to provide ambient notifications for energy management. The study, published in 2018, details its implementation and interaction design for contextual awareness in renewable energy systems.\n"
     ]
    }
   ],
   "source": [
    "# Create a chat history with a system message and a human message\n",
    "binded_llm = llm.bind(stop=[\"Observation:\"])\n",
    "history = [SystemMessage(content=instructions)]\n",
    "agent = Agent(llm=binded_llm, tools=tools, history=history)\n",
    "agent.invoke(PROMPT0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3da453f",
   "metadata": {},
   "source": [
    "# Retrieval Integrated Generation (RIG)\n",
    "Retrieval Integrated Generation (RIG) is a technique that combines the strengths of retrieval-based and generation-based approaches to improve the quality and relevance of generated responses. It involves retrieving relevant information from a knowledge base or database only when the model asks for it and then using that information to generate more accurate and contextually appropriate responses."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
