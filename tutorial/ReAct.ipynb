{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "860bdd6d",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(255, 0, 0, 0.5); padding: 10px; border-radius: 5px; width: 95%\">\n",
    "\n",
    "### **Limited autonomy of Large Language Models (LLMs)**\n",
    "\n",
    "Large Language Models (LLMs) do not have real-time awareness or access to current events. Their knowledge is based on static training data with a fixed cut-off date.\n",
    "They also cannot browse the web, run code, or interact with live tools unless explicitly connected to such systems.\n",
    "\n",
    "As a result, when asked questions that require up-to-date information or external actions, LLMs may:\n",
    "\n",
    "- Provide outdated, inaccurate, or nonsensical answers, **or**\n",
    "- Admit they don’t know the answer.\n",
    "\n",
    "**Example:**  \n",
    "-  Ask the chatbot: _\"What time is it?\"_  \n",
    "- and observe how it responds.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42159320",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(0, 0, 0, 0.5); padding: 10px; border-radius: 5px; width: 95%\">\n",
    "\n",
    "### **Purpose of the Notebook**\n",
    "The goal of the notebook is to demonstrate how to overcome the limited autonomy of LLMs by connecting them to external tools and APIs, enabling them to access real-time information and perform actions beyond their static training data.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0485eea1",
   "metadata": {},
   "source": [
    "# Define Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "93995f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_BASE_URL = \"http://localhost:11434\"\n",
    "LLM_MODEL = \"qwen3:8b\" # mistral bad, mistral-small ok, qwen3:8b impressive\n",
    "# minimize randomness for reproducibility\n",
    "LLM_SEED = 42 \n",
    "LLM_TEMPERATURE = 0.0\n",
    "TEST_PROMPT0 = \"What time is it?\"\n",
    "TEST_PROMPT1 = \"What is the price of gold right now?\" \n",
    "TEST_PROMPT3 = \"How many 1 in 111111111111111?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eff3793",
   "metadata": {},
   "source": [
    "# Initialize Ollama Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "267b6691",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# Set up the Ollama chat model with specified LLM model and parameters\n",
    "llm = ChatOllama(\n",
    "    base_url=OLLAMA_BASE_URL,\n",
    "    model=LLM_MODEL,\n",
    "    temperature=LLM_TEMPERATURE,\n",
    "    seed=LLM_SEED,\n",
    "    stream=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4cb34e",
   "metadata": {},
   "source": [
    "# Define Tools\n",
    "\n",
    "1. **Python Tool:** This tool allows the chatbot to execute Python code, enabling it to perform calculations, data processing, and other tasks that require programming logic.\n",
    "\n",
    "2. **Commodity Price Tool:** This tool fetches real-time commodity prices from the `API Ninjas` API, allowing the chatbot to provide up-to-date information on various commodities.\n",
    "    - Go to [``API Ninjas``](https://api-ninjas.com/)\n",
    "    - Click the \"Sign Up\" button\n",
    "    - Create an account\n",
    "    - Log in\n",
    "    - Click the \"My Account\" button\n",
    "    - Click the \"Show API Key\" button\n",
    "\n",
    "    In the next cell, you will need to:\n",
    "    - Replace the content of the variable `NINJA_API_KEY` with your API key.\n",
    "    - Run the cell to test the API tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "88126c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, World!\n",
      "Error 400: {\"error\": \"Invalid API Key.\"}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool, Tool\n",
    "from typing import Annotated, List\n",
    "import io\n",
    "import contextlib\n",
    "import requests\n",
    "\n",
    "NINJA_API_KEY = \"YOUR_API_KEY\"\n",
    "\n",
    "@tool\n",
    "def execute_python(py_code: Annotated[str, \"Python code to execute\"]) -> str:\n",
    "    \"\"\"Executes a Python code and returns its standard output (you have to use the print() function).\"\"\"\n",
    "    output = io.StringIO()\n",
    "    try:\n",
    "        with contextlib.redirect_stdout(output):\n",
    "            exec(py_code, {})\n",
    "        return output.getvalue().strip() or \"Code executed with no output.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Test the tool\n",
    "print(execute_python.invoke(\"print('Hello, World!')\"))\n",
    "\n",
    "@tool\n",
    "def get_commodity_price(\n",
    "    commodity: Annotated[str, \"The name of the commodity to get the price for\"]\n",
    ") -> str:\n",
    "    \"\"\"Get the current price of a commodity using the Ninja API.\"\"\"\n",
    "    api_url = 'https://api.api-ninjas.com/v1/commodityprice?name={}'.format(commodity)\n",
    "    response = requests.get(api_url, headers={'X-Api-Key': NINJA_API_KEY})\n",
    "    if response.status_code == requests.codes.ok:\n",
    "        return response.text\n",
    "    else:\n",
    "        return f\"Error {response.status_code}: {response.text}\"\n",
    "\n",
    "#Test the tool\n",
    "print(get_commodity_price.invoke(\"gold\"))\n",
    "    \n",
    "tools = [execute_python, get_commodity_price]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48ad674",
   "metadata": {},
   "source": [
    "# Prepare Reason-and-Act (ReAct) Instructions\n",
    "\n",
    "ReAct (Reason-and-Act) prompting combines:\n",
    "\n",
    "- **Reasoning:** The model explains its thinking process.\n",
    "- **Acting:** The model chooses and performs actions (like using a calculator, web search, or database query).\n",
    "\n",
    "The prompt encourages the model to alternate between these two steps, creating a loop:\n",
    "\n",
    "→ Think → Act → Observe → Think → Act → … until the task is complete.\n",
    "\n",
    "**Reference:**\n",
    "\n",
    "(Yao et al., 2023) Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K., & Cao, Y. (2023, January). ReAct: Synergizing reasoning and acting in language models. In *International Conference on Learning Representations (ICLR)*.]{https://doi.org/10.48550/arXiv.2210.03629}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "03f08829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following questions as best you can.\n",
      "You can answer directly if the user is greeting you or similar.\n",
      "Otherwise, you have access to the following tools:\n",
      "\n",
      "execute_python(py_code: Annotated[str, 'Python code to execute']) -> str - Executes a Python code and returns its standard output (you have to use the print() function).\n",
      "get_commodity_price(commodity: Annotated[str, 'The name of the commodity to get the price for']) -> str - Get the current price of a commodity using the Ninja API.\n",
      "\n",
      "The way you use the tools is by specifying a json blob.\n",
      "Specifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\n",
      "\n",
      "The only values that should be in the \"action\" field are: execute_python, get_commodity_price\n",
      "\n",
      "The $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"action\": $TOOL_NAME,\n",
      "  \"action_input\": $INPUT\n",
      "}\n",
      "```\n",
      "\n",
      "ALWAYS use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action:\n",
      "```\n",
      "$JSON_BLOB\n",
      "```\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin! Reminder to always use the exact characters `Final Answer:` when responding.\n",
      "Always make your final answer easy to read and understand for humans.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "from inspect import signature\n",
    "\n",
    "tools_names = \", \".join([tool.name for tool in tools])\n",
    "tools_descriptions = \"\\n\".join([f\"{tool.name}{signature(tool.func)} - {tool.description}\" for tool in tools]) \n",
    "\n",
    "\n",
    "# Taken from https://smith.langchain.com/hub/hwchase17/react-json\n",
    "instructions = f\"\"\"Answer the following questions as best you can.\n",
    "You can answer directly if the user is greeting you or similar.\n",
    "Otherwise, you have access to the following tools:\n",
    "\n",
    "{tools_descriptions}\n",
    "\n",
    "The way you use the tools is by specifying a json blob.\n",
    "Specifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\n",
    "\n",
    "The only values that should be in the \"action\" field are: {tools_names}\n",
    "\n",
    "The $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\n",
    "\n",
    "```\n",
    "{{\n",
    "  \"action\": $TOOL_NAME,\n",
    "  \"action_input\": $INPUT\n",
    "}}\n",
    "```\n",
    "\n",
    "ALWAYS use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action:\n",
    "```\n",
    "$JSON_BLOB\n",
    "```\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin! Reminder to always use the exact characters `Final Answer:` when responding.\n",
    "Always make your final answer easy to read and understand for humans.\n",
    "\"\"\"\n",
    "\n",
    "print(instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ab489e",
   "metadata": {},
   "source": [
    "# Create a Chatbot Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "960f5e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain.schema import BaseMessage, AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "class Chatbot:\n",
    "    llm: ChatOllama\n",
    "    history: List[BaseMessage]\n",
    "\n",
    "    def __init__(self, llm: ChatOllama, history: List[BaseMessage] = []):\n",
    "        \"\"\"Initialize the chatbot with an LLM and an optional history.\"\"\"\n",
    "        self.llm = llm\n",
    "        self.history = history\n",
    "    \n",
    "    def invoke(self, prompt:str) -> None:\n",
    "        \"\"\"Run the chatbot with the current history.\"\"\"\n",
    "        clear_output(wait=True)\n",
    "        self.pretty_print()\n",
    "        human_message = HumanMessage(content=prompt)\n",
    "        human_message.pretty_print()\n",
    "        self.history.append(human_message)\n",
    "        ai_message = AIMessage(content=\"\")\n",
    "        ai_message.pretty_print()\n",
    "        print()\n",
    "        for chunk in self.llm.stream(self.history):\n",
    "            print(chunk.content, end=\"\")\n",
    "            ai_message.content += chunk.content\n",
    "        print()\n",
    "        self.history.append(ai_message)\n",
    "        \n",
    "    \n",
    "    def interact(self) -> None:\n",
    "        \"\"\"Run the chatbot in interactive mode.\"\"\"\n",
    "        while True: \n",
    "            prompt = input(\"Prompt (Enter 'stop' to exit)\")\n",
    "            if prompt == \"stop\": \n",
    "                break\n",
    "            self.invoke(prompt)\n",
    "\n",
    "\n",
    "    def pretty_print(self) -> None:\n",
    "        \"\"\"Pretty print the chatbot's history.\"\"\"\n",
    "        for message in self.history:\n",
    "            message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be529b36",
   "metadata": {},
   "source": [
    "# Test the Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "8ef58eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a chat history with a system message and a human message\n",
    "history = [SystemMessage(content=instructions)]\n",
    "chatbot = Chatbot(llm=llm, history=history)\n",
    "# chatbot.invoke(TEST_PROMPT0)\n",
    "# chatbot.interact()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cee0b09",
   "metadata": {},
   "source": [
    "<div style= \"padding: 0.5em;background-color: rgba(255,0,0, 0.5);width: 95%\">\n",
    "\n",
    "### **Problem:** the LLM generated the observation and should have waited for the tool response\n",
    "\n",
    "Here, we did not interrupt the LLM when it generated the keyword *\"Observation:\"*. Meaning that we did not actually call the tool. Hence, the LLM hallucinated and made up a response.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459bfd24",
   "metadata": {},
   "source": [
    "# Interrupting the chatbot when generating '*Observations:*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "7a8e7d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "binded_llm = llm.bind(stop=[\"Observation:\"])\n",
    "history = [SystemMessage(content=instructions)]\n",
    "chatbot = Chatbot(llm=binded_llm, history=history)\n",
    "#chatbot.invoke(TEST_PROMPT0)\n",
    "#chatbot.interact()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a1b9e4",
   "metadata": {},
   "source": [
    "# Create an Agent Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "4ea10267",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import BaseMessage, AIMessage, HumanMessage, SystemMessage\n",
    "import re\n",
    "from typing import Union\n",
    "from langchain_core.agents import AgentAction, AgentFinish, AgentActionMessageLog\n",
    "from langchain_core.exceptions import OutputParserException\n",
    "from langchain.agents.agent import AgentOutputParser\n",
    "from langchain.agents.chat.prompt import FORMAT_INSTRUCTIONS\n",
    "import ast\n",
    "from IPython.display import clear_output, display\n",
    "from langchain_core.messages import ToolMessage\n",
    "import traceback\n",
    "import sys\n",
    "\n",
    "class Agent(Chatbot):\n",
    "\n",
    "    tools: List[Tool]\n",
    "    \n",
    "    def __init__(self, llm: ChatOllama, tools: List[Tool], history: List[BaseMessage] = []):\n",
    "        \"\"\"Initialize the chatbot with an LLM, tools, and an optional history.\"\"\"\n",
    "        super().__init__(llm, history)\n",
    "        self.tools = tools\n",
    "\n",
    "    def invoke(self, prompt:str) -> None:\n",
    "        \"\"\"Run the chatbot in interactive mode.\"\"\"\n",
    "        self.history.append(HumanMessage(content=prompt))\n",
    "        clear_output(wait=True)\n",
    "        self.pretty_print()\n",
    "        stop = False\n",
    "        while not stop:\n",
    "            ai_pre_action_message = self.llm.invoke(self.history)\n",
    "            self.history.append(ai_pre_action_message)\n",
    "            try:\n",
    "                action = self.parse_action(ai_pre_action_message.content)\n",
    "                if isinstance(action, AgentAction):\n",
    "                    tool_message = self.call_tool(action)\n",
    "                    self.history.append(tool_message)\n",
    "                if isinstance(action, AgentFinish):\n",
    "                    stop = True\n",
    "            except SyntaxError as e:\n",
    "                self.history.append(SystemMessage(content=str(e)))\n",
    "            except Exception as e:\n",
    "                traceback.print_exc()\n",
    "                sys.exit()\n",
    "            clear_output(wait=True)\n",
    "            self.pretty_print()\n",
    "\n",
    "\n",
    "    def call_tool(self, action: AgentAction) -> ToolMessage:\n",
    "        \"\"\"Call the specified tool with the given action input.\"\"\"\n",
    "        tool = next((t for t in self.tools if t.name == action.tool), None)\n",
    "        if not tool:\n",
    "            return ToolMessage(content=f\"Error: Tool '{action.tool}' does not exist.\", tool_call_id=\"unknown_tool\")\n",
    "        result = None\n",
    "        sig = signature(tool.func)\n",
    "        if len(sig.parameters):\n",
    "            action_input = action.tool_input\n",
    "            if not isinstance(action_input, dict):\n",
    "                param_name = next(iter(sig.parameters))\n",
    "                action_input = {param_name: action_input}\n",
    "            result = tool.func(**action_input)\n",
    "        else:\n",
    "            result = tool.func()\n",
    "        return ToolMessage(content=f\"Observation: {result}\", tool_call_id=tool.func.__name__)\n",
    "    \n",
    "    \n",
    "    def parse_action(self, text:str) -> Union[AgentAction, AgentActionMessageLog, AgentFinish]:\n",
    "        \"\"\"Parse the action from the LLM output text and return an AgentAction or AgentFinish object.\"\"\"\n",
    "        FINAL_ANSWER_ACTION = \"Final Answer:\"\n",
    "        pattern = re.compile(r\"^.*?`{3}(?:json)?\\n?(.*?)`{3}.*?$\", re.DOTALL)\n",
    "        includes_answer = FINAL_ANSWER_ACTION in text\n",
    "        try:\n",
    "            found = pattern.search(text)\n",
    "            if not found:\n",
    "                raise ValueError(\"action not found.\")\n",
    "            action = found.group(1)\n",
    "            response = ast.literal_eval(action.strip())\n",
    "            return AgentAction(response[\"action\"], response.get(\"action_input\", {}), text)\n",
    "        except Exception as e:\n",
    "            if not includes_answer:\n",
    "                raise SyntaxError(\"Reminder to always use the exact characters `Final Answer:` when responding.\")\n",
    "            output = text.split(FINAL_ANSWER_ACTION)[-1].strip()\n",
    "            return AgentFinish({\"output\": output}, text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91e0dea",
   "metadata": {},
   "source": [
    "# Testing the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "9d90d63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "Answer the following questions as best you can.\n",
      "You can answer directly if the user is greeting you or similar.\n",
      "Otherwise, you have access to the following tools:\n",
      "\n",
      "execute_python(py_code: Annotated[str, 'Python code to execute']) -> str - Executes a Python code and returns its standard output (you have to use the print() function).\n",
      "get_commodity_price(commodity: Annotated[str, 'The name of the commodity to get the price for']) -> str - Get the current price of a commodity using the Ninja API.\n",
      "\n",
      "The way you use the tools is by specifying a json blob.\n",
      "Specifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\n",
      "\n",
      "The only values that should be in the \"action\" field are: execute_python, get_commodity_price\n",
      "\n",
      "The $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"action\": $TOOL_NAME,\n",
      "  \"action_input\": $INPUT\n",
      "}\n",
      "```\n",
      "\n",
      "ALWAYS use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action:\n",
      "```\n",
      "$JSON_BLOB\n",
      "```\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin! Reminder to always use the exact characters `Final Answer:` when responding.\n",
      "Always make your final answer easy to read and understand for humans.\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What time is it?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<think>\n",
      "Okay, the user is asking, \"What time is it?\" Let me think about how to handle this.\n",
      "\n",
      "First, I need to check if any of the provided tools can help answer this. The available tools are execute_python and get_commodity_price. \n",
      "\n",
      "The get_commodity_price tool is for getting commodity prices, which isn't related to time. The execute_python tool can run Python code. Maybe I can use Python to get the current time. \n",
      "\n",
      "But wait, the user might be expecting the assistant to know the time without executing code. However, since the tools don't include a clock or time API, the correct approach is to use the execute_python tool to run a Python script that prints the current time. \n",
      "\n",
      "So, I'll generate a Python code snippet that uses datetime to get the current time and prints it. Then, the tool will execute this code and return the output. \n",
      "\n",
      "I need to make sure the JSON blob is correctly formatted with the action and action_input. The Python code should be a string in the action_input. \n",
      "\n",
      "Let me draft the Python code: import datetime and print the current time. Then, the observation will capture that output, and I can relay it back to the user as the final answer.\n",
      "</think>\n",
      "\n",
      "Thought: I don't have access to real-time data like the current time. However, I can use Python to get the current time.\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"execute_python\",\n",
      "  \"action_input\": \"import datetime\\nprint(datetime.datetime.now().strftime('%H:%M:%S'))\"\n",
      "}\n",
      "```\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "Observation: 15:10:31\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<think>\n",
      "Okay, the user asked, \"What time is it?\" I used the execute_python tool to run a script that gets the current time and formats it as HH:MM:SS. The observation returned was \"15:10:31\". That's the time in 24-hour format. I need to present this to the user clearly. Since the user might be in a time zone where 15:10:31 is the correct local time, I should just state that as the current time. No need for additional conversions unless the user specifies a different time zone, which they didn't. So the final answer is simply the time retrieved.\n",
      "</think>\n",
      "\n",
      "Final Answer: The current time is 15:10:31.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the price of gold right now?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<think>\n",
      "Okay, the user is asking for the current price of gold. Let me check which tools I have available. There's the get_commodity_price function that uses the Ninja API. I need to make sure to use the correct commodity name. Gold is typically referred to as \"gold\" in such contexts. So I should call get_commodity_price with \"gold\" as the input. Let me structure the JSON blob properly. The action is get_commodity_price, and the action_input is \"gold\". That's all I need. Let me double-check if there are any other possible names, but I think \"gold\" is the right one here. Alright, time to send that.\n",
      "</think>\n",
      "\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"get_commodity_price\",\n",
      "  \"action_input\": \"gold\"\n",
      "}\n",
      "```\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "Observation: Error 400: {\"error\": \"Invalid API Key.\"}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<think>\n",
      "Okay, the user asked for the price of gold, and I tried using the get_commodity_price tool, but it returned an error about an invalid API key. Hmm, maybe the Ninja API requires a valid key that I don't have access to. Since I can't retrieve the price without a valid key, I should inform the user that I can't access real-time data and suggest they check a financial service or website for the latest gold prices. Let me make sure I don't mention any tools again since the API isn't working. Alright, time to craft a helpful response.\n",
      "</think>\n",
      "\n",
      "Final Answer: I currently cannot access real-time commodity prices, including gold. For the latest gold price, please check a financial news website, trading platform, or a currency converter service that provides real-time market data.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a chat history with a system message and a human message\n",
    "binded_llm = llm.bind(stop=[\"Observation:\"])\n",
    "history = [SystemMessage(content=instructions)]\n",
    "agent = Agent(llm=binded_llm, tools=tools, history=history)\n",
    "agent.invoke(TEST_PROMPT0)\n",
    "agent.invoke(TEST_PROMPT1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be09a7a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
