{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "860bdd6d",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(255, 0, 0, 0.5); padding: 10px; border-radius: 5px; width: 95%\">\n",
    "\n",
    "### ðŸ”’ **Empowering LLMs with External Tools**\n",
    "\n",
    "Large Language Models (LLMs) operate based on static training data and do **not** have real-time awareness or built-in access to current events, live systems, or external APIs.  \n",
    "Unless explicitly integrated with such tools, they:\n",
    "\n",
    "- Cannot browse the web  \n",
    "- Cannot run code  \n",
    "- Cannot interact with real-time data sources\n",
    "\n",
    "As a result, when asked questions that require up-to-date knowledge or external action, LLMs may:\n",
    "\n",
    "- Provide outdated, inaccurate, or fabricated responses, **or**\n",
    "- Acknowledge their limitations and defer the question\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color:rgba(0, 0, 0, 0.5); padding: 10px; border-radius: 5px; width: 95%\">\n",
    "\n",
    "### ðŸš€ **Purpose of This Notebook**\n",
    "\n",
    "This notebook explores how to **extend the capabilities** of LLMs by connecting them to external tools and APIs.  \n",
    "By integrating real-time services, we can:\n",
    "\n",
    "- Enable live data access  \n",
    "- Perform dynamic computations  \n",
    "- Interact with the environment beyond the training corpus\n",
    "\n",
    "The goal is to demonstrate practical techniques for transforming LLMs from passive text generators into **interactive, tool-empowered agents**.\n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59eefbf0",
   "metadata": {},
   "source": [
    "# Start Ollama Server\n",
    "\n",
    "1. Open a terminal\n",
    "\n",
    "    â˜° > *Terminal* > *New Terminal*\n",
    "\n",
    "2. Start the Ollama server \n",
    "\n",
    "    ```bash\n",
    "    ollama serve\n",
    "    ```\n",
    "\n",
    "3. Do not close this terminal\n",
    "\n",
    "4. Open another terminal\n",
    "5. Pull the model *\"qwen3:4b\"* (if not already done)\n",
    "\n",
    "    ```bash\n",
    "    ollama pull qwen3:4b\n",
    "    ```\n",
    "5. Close this terminal\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0485eea1",
   "metadata": {},
   "source": [
    "# Define Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93995f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_BASE_URL = \"http://localhost:11434\"\n",
    "LLM_MODEL = \"qwen3:4b\"\n",
    "LLM_SEED = 42 \n",
    "LLM_TEMPERATURE = 0.0\n",
    "TEST_PROMPT0 = \"What time is it?\"\n",
    "TEST_PROMPT1 = \"What is the price of gold right now?\" \n",
    "TEST_PROMPT2 = \"How many 1 in 111111111111111?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eff3793",
   "metadata": {},
   "source": [
    "# Initialize Ollama Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267b6691",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# Set up the Ollama chat model with specified LLM model and parameters\n",
    "llm = ChatOllama(\n",
    "    base_url=OLLAMA_BASE_URL,\n",
    "    model=LLM_MODEL,\n",
    "    temperature=LLM_TEMPERATURE,\n",
    "    seed=LLM_SEED,\n",
    "    stream=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4cb34e",
   "metadata": {},
   "source": [
    "# Define Tools\n",
    "\n",
    "1. **Python Tool:** This tool allows the chatbot to execute Python code, enabling it to perform calculations, data processing, and other tasks that require programming logic.\n",
    "\n",
    "2. **Commodity Price Tool:** This tool fetches real-time commodity prices from the `API Ninjas` API, allowing the chatbot to provide up-to-date information on various commodities.\n",
    "    - Go to [``API Ninjas``](https://api-ninjas.com/)\n",
    "    - Click the \"Sign Up\" button\n",
    "    - Create an account\n",
    "    - Log in\n",
    "    - Click the \"My Account\" button\n",
    "    - Click the \"Show API Key\" button\n",
    "\n",
    "    In the next cell, you will need to:\n",
    "    - Replace the content of the variable `NINJA_API_KEY` with your API key.\n",
    "    - Run the cell to test the API tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88126c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool, Tool\n",
    "from typing import Annotated, List\n",
    "import io\n",
    "import contextlib\n",
    "import requests\n",
    "\n",
    "NINJA_API_KEY = \"MdaCcVUHseixkwpNGhumWg==9mb676ZThl4du9aP\"\n",
    "\n",
    "@tool\n",
    "def execute_python(py_code: Annotated[str, \"Python code to execute\"]) -> str:\n",
    "    \"\"\"Executes a Python code and returns its standard output (you have to use the print() function).\"\"\"\n",
    "    output = io.StringIO()\n",
    "    try:\n",
    "        with contextlib.redirect_stdout(output):\n",
    "            exec(py_code, {})\n",
    "        return output.getvalue().strip() or \"Code executed with no output.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Test the tool\n",
    "print(execute_python.invoke(\"print('Hello, World!')\"))\n",
    "\n",
    "@tool\n",
    "def get_commodity_price(\n",
    "    commodity: Annotated[str, \"The name of the commodity to get the price for\"]\n",
    ") -> str:\n",
    "    \"\"\"Get the current price of a commodity using the Ninja API.\"\"\"\n",
    "    api_url = 'https://api.api-ninjas.com/v1/commodityprice?name={}'.format(commodity)\n",
    "    response = requests.get(api_url, headers={'X-Api-Key': NINJA_API_KEY})\n",
    "    if response.status_code == requests.codes.ok:\n",
    "        return response.text\n",
    "    else:\n",
    "        return f\"Error {response.status_code}: {response.text}\"\n",
    "\n",
    "#Test the tool\n",
    "print(get_commodity_price.invoke(\"gold\"))\n",
    "    \n",
    "tools = [execute_python, get_commodity_price]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48ad674",
   "metadata": {},
   "source": [
    "# Prepare Reason-and-Act (ReAct) Instructions\n",
    "\n",
    "ReAct (Reason-and-Act) prompting combines:\n",
    "\n",
    "- **Reasoning:** The model explains its thinking process.\n",
    "- **Acting:** The model chooses and performs actions (like using a calculator, web search, or database query).\n",
    "\n",
    "The prompt encourages the model to alternate between these two steps, creating a loop:\n",
    "\n",
    "â†’ Think â†’ Act â†’ Observe â†’ Think â†’ Act â†’ â€¦ until the task is complete.\n",
    "\n",
    "**Reference:**\n",
    "\n",
    "(Yao et al., 2023) Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K., & Cao, Y. (2023, January). ReAct: Synergizing reasoning and acting in language models. In *International Conference on Learning Representations (ICLR)*.]{https://doi.org/10.48550/arXiv.2210.03629}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f08829",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "from inspect import signature\n",
    "\n",
    "tools_descriptions = \"\\n- \".join([f\"{tool.name}{signature(tool.func)} - {tool.description}\" for tool in tools]) \n",
    "\n",
    "# Taken from https://smith.langchain.com/hub/hwchase17/react-json\n",
    "instructions = f\"\"\"You are a reasoning and acting assistant. You solve complex tasks by thinking step-by-step and using tools when needed. Follow this format exactly:\n",
    "\n",
    "Question: (The user's question or task.)\n",
    "\n",
    "Thought: (Think about what to do next.)\n",
    "\n",
    "Action: (What tool to use, if any, and what input to provide. Use the exact JSON format below.)\n",
    "```\n",
    "{{\n",
    "  \"action\": $TOOL_NAME,\n",
    "  \"action_input\": $TOOL_INPUT\n",
    "}}\n",
    "```\n",
    "\n",
    "Observation: (What was the result of the action.)\n",
    "\n",
    "... (Repeat Thought â†’ Action â†’ Observation as needed)\n",
    "\n",
    "Final Answer: (Your final response to the user.)\n",
    "\n",
    "Important Rules:\n",
    "- Always begin with a Thought before taking an action.\n",
    "- If an action is needed, use the following format:\n",
    "  Action: \n",
    "  ```\n",
    "  {{\n",
    "    \"action\": \"tool_name\",\n",
    "    \"action_input\": \"your input here\"\n",
    "  }}\n",
    "  ```\n",
    "- If you want to give your final answer, use the following format:\n",
    "  Final Answer: \n",
    "  ```\n",
    "  your final answer here\n",
    "  ```\n",
    "\n",
    "Available Tools:\n",
    "- {tools_descriptions}\n",
    "\n",
    "Think clearly. Be concise. Don't skip steps.\n",
    "\"\"\"\n",
    "\n",
    "print(instructions)\n",
    "print(instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be529b36",
   "metadata": {},
   "source": [
    "# Test the Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef58eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.Chatbot import Chatbot\n",
    "from langchain_core.messages import SystemMessage\n",
    "# Create a chat history with a system message and a human message\n",
    "chatbot = Chatbot(llm=llm, history=[SystemMessage(content=instructions)])\n",
    "chatbot.invoke(TEST_PROMPT0)\n",
    "# chatbot.interact()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cee0b09",
   "metadata": {},
   "source": [
    "<div style= \"padding: 0.5em;background-color: rgba(255,0,0, 0.5);width: 95%\">\n",
    "\n",
    "### **Problem:** the LLM generated the observation and should have waited for the tool response\n",
    "\n",
    "Here, we did not interrupt the LLM when it generated the keyword *\"Observation:\"*. Meaning that we did not actually call the tool. Hence, the LLM hallucinated and made up a response.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459bfd24",
   "metadata": {},
   "source": [
    "# Interrupting the chatbot when generating '*Observations:*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8e7d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "binded_llm = llm.bind(stop=[\"Observation:\"])\n",
    "history = [SystemMessage(content=instructions)]\n",
    "chatbot = Chatbot(llm=binded_llm, history=history)\n",
    "chatbot.invoke(TEST_PROMPT0)\n",
    "#chatbot.interact()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a1b9e4",
   "metadata": {},
   "source": [
    "# Create an Agent Class\n",
    "\n",
    "<div style=\"background-color:rgba(0, 0, 0, 0); padding: 10px; border: 1px solid rgba(255, 255, 255, 1); border-radius: 5px; width: 95%; margin: 10px auto; text-align: center;\">\n",
    "\n",
    "### ðŸ“Š Conversation Flow Diagram\n",
    "\n",
    "```mermaid\n",
    "flowchart LR\n",
    "   State0((START))\n",
    "   State1(ReAct Instructions)\n",
    "   State2(Assistant)\n",
    "   State4(Tools)\n",
    "   State3(Human)\n",
    "   State5((END))\n",
    "   State0 --> State1\n",
    "   State1 -- SystemMessage --> State2\n",
    "   State2 -- AiMessage --> State3\n",
    "   State2 -- AiMessage --> State4\n",
    "   State4 -- ToolMessage --> State2\n",
    "\n",
    "   State3 -- HumanMessage --> State2\n",
    "   State3 -- type `stop` --> State5\n",
    "```\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea10267",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.Chatbot import Chatbot\n",
    "from src.Agent import Agent \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91e0dea",
   "metadata": {},
   "source": [
    "# Testing the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d90d63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a chat history with a system message and a human message\n",
    "agent = Agent(llm=llm, tools=tools, history=[SystemMessage(content=instructions)])\n",
    "agent.invoke(TEST_PROMPT0)\n",
    "agent.invoke(TEST_PROMPT1)\n",
    "agent.invoke(TEST_PROMPT2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10822772",
   "metadata": {},
   "source": [
    "### To go further\n",
    "\n",
    " Explore Model Context Protocol (MCP) which allows you to make your tools and APIs publicly available to the LLMs.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
