{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "860bdd6d",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(255, 0, 0, 0.5); padding: 10px; border-radius: 5px; width: 95%\">\n",
    "\n",
    "### ðŸ”’ **Empowering LLMs with External Tools**\n",
    "\n",
    "Large Language Models (LLMs) operate based on static training data and do **not** have real-time awareness or built-in access to current events, live systems, or external APIs.  \n",
    "Unless explicitly integrated with such tools, they:\n",
    "\n",
    "- Cannot browse the web  \n",
    "- Cannot run code  \n",
    "- Cannot interact with real-time data sources\n",
    "\n",
    "As a result, when asked questions that require up-to-date knowledge or external action, LLMs may:\n",
    "\n",
    "- Provide outdated, inaccurate, or fabricated responses, **or**\n",
    "- Acknowledge their limitations and defer the question\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color:rgba(0, 0, 0, 0.5); padding: 10px; border-radius: 5px; width: 95%\">\n",
    "\n",
    "### ðŸš€ **Purpose of This Notebook**\n",
    "\n",
    "This notebook explores how to **extend the capabilities** of LLMs by connecting them to external tools and APIs.  \n",
    "By integrating real-time services, we can:\n",
    "\n",
    "- Enable live data access  \n",
    "- Perform dynamic computations  \n",
    "- Interact with the environment beyond the training corpus\n",
    "\n",
    "The goal is to demonstrate practical techniques for transforming LLMs from passive text generators into **interactive, tool-empowered agents**.\n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59eefbf0",
   "metadata": {},
   "source": [
    "# Start Ollama Server\n",
    "\n",
    "1. Open a terminal\n",
    "\n",
    "    â˜° > *Terminal* > *New Terminal*\n",
    "\n",
    "2. Start the Ollama server \n",
    "\n",
    "    ```bash\n",
    "    ollama serve\n",
    "    ```\n",
    "\n",
    "3. Do not close this terminal\n",
    "\n",
    "4. Open another terminal\n",
    "5. Pull the model *\"qwen3:4b\"* (if not already done)\n",
    "\n",
    "    ```bash\n",
    "    ollama pull qwen3:4b\n",
    "    ```\n",
    "5. Close this terminal\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0485eea1",
   "metadata": {},
   "source": [
    "# Define Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93995f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_BASE_URL = \"http://localhost:11434\"\n",
    "LLM_MODEL = \"qwen3:4b\"\n",
    "LLM_SEED = 42\n",
    "LLM_TEMPERATURE = 0.0\n",
    "TEST_PROMPT0 = \"What time is it?\"\n",
    "TEST_PROMPT1 = \"What is the price of gold right now?\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eff3793",
   "metadata": {},
   "source": [
    "# Initialize Ollama Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "267b6691",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# Set up the Ollama chat model with specified LLM model and parameters\n",
    "llm = ChatOllama(\n",
    "    base_url=OLLAMA_BASE_URL,\n",
    "    model=LLM_MODEL,\n",
    "    temperature=LLM_TEMPERATURE,\n",
    "    seed=LLM_SEED,\n",
    "    stream=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4cb34e",
   "metadata": {},
   "source": [
    "# Define Tools\n",
    "\n",
    "1. **Python Tool:** This tool allows the chatbot to execute Python code, enabling it to perform calculations, data processing, and other tasks that require programming logic.\n",
    "\n",
    "2. **Commodity Price Tool:** This tool fetches real-time commodity prices from the `API Ninjas` API, allowing the chatbot to provide up-to-date information on various commodities.\n",
    "    - Go to [``API Ninjas``](https://api-ninjas.com/)\n",
    "    - Click the \"Sign Up\" button\n",
    "    - Create an account\n",
    "    - Log in\n",
    "    - Click the \"My Account\" button\n",
    "    - Click the \"Show API Key\" button\n",
    "\n",
    "    In the next cell, you will need to:\n",
    "    - Replace the content of the variable `NINJA_API_KEY` with your API key.\n",
    "    - Run the cell to test the API tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88126c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, World!\n",
      "{\"exchange\": \"CME\", \"name\": \"Gold Futures\", \"price\": 3389.4, \"updated\": 1750677111}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool, Tool\n",
    "from typing import Annotated, List\n",
    "import io\n",
    "import contextlib\n",
    "import requests\n",
    "\n",
    "NINJA_API_KEY = \"MdaCcVUHseixkwpNGhumWg==9mb676ZThl4du9aP\"\n",
    "\n",
    "@tool\n",
    "def execute_python(py_code: Annotated[str, \"Python code to execute\"]) -> str:\n",
    "    \"\"\"Executes a Python code and returns its standard output (you have to use the print() function).\"\"\"\n",
    "    output = io.StringIO()\n",
    "    try:\n",
    "        with contextlib.redirect_stdout(output):\n",
    "            exec(py_code, {})\n",
    "        return output.getvalue().strip() or \"Code executed with no output.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Test the tool\n",
    "print(execute_python.invoke(\"print('Hello, World!')\"))\n",
    "\n",
    "@tool\n",
    "def get_commodity_price(\n",
    "    commodity: Annotated[str, \"The name of the commodity to get the price for\"]\n",
    ") -> str:\n",
    "    \"\"\"Get the current price of a commodity using the Ninja API.\"\"\"\n",
    "    api_url = 'https://api.api-ninjas.com/v1/commodityprice?name={}'.format(commodity)\n",
    "    response = requests.get(api_url, headers={'X-Api-Key': NINJA_API_KEY})\n",
    "    if response.status_code == requests.codes.ok:\n",
    "        return response.text\n",
    "    else:\n",
    "        return f\"Error {response.status_code}: {response.text}\"\n",
    "\n",
    "#Test the tool\n",
    "print(get_commodity_price.invoke(\"gold\"))\n",
    "    \n",
    "tools = [execute_python, get_commodity_price]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48ad674",
   "metadata": {},
   "source": [
    "# Prepare Reason-and-Act (ReAct) Instructions\n",
    "\n",
    "ReAct (Reason-and-Act) prompting combines:\n",
    "\n",
    "- **Reasoning:** The model explains its thinking process.\n",
    "- **Acting:** The model chooses and performs actions (like using a calculator, web search, or database query).\n",
    "\n",
    "The prompt encourages the model to alternate between these two steps, creating a loop:\n",
    "\n",
    "â†’ Think â†’ Act â†’ Observe â†’ Think â†’ Act â†’ â€¦ until the task is complete.\n",
    "\n",
    "**Reference:**\n",
    "\n",
    "(Yao et al., 2023) Yao, S., Zhao, J., Yu, D., Du, N., Shafran, I., Narasimhan, K., & Cao, Y. (2023, January). ReAct: Synergizing reasoning and acting in language models. In *International Conference on Learning Representations (ICLR)*.]{https://doi.org/10.48550/arXiv.2210.03629}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03f08829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"You are a reasoning and acting assistant. Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "execute_python(py_code: Annotated[str, 'Python code to execute']) -> str - Executes a Python code and returns its standard output (you have to use the print() function).\n",
      "get_commodity_price(commodity: Annotated[str, 'The name of the commodity to get the price for']) -> str - Get the current price of a commodity using the Ninja API.\n",
      "\n",
      "The way you use the tools is by specifying a json blob.\n",
      "Specifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\n",
      "\n",
      "The only values that should be in the \"action\" field are: ['execute_python', 'get_commodity_price']\n",
      "\n",
      "The $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\n",
      "\n",
      "```\n",
      "{\n",
      "  \"action\": $TOOL_NAME,\n",
      "  \"action_input\": $INPUT\n",
      "}\n",
      "```\n",
      "\n",
      "ALWAYS use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action:\n",
      "```\n",
      "$JSON_BLOB\n",
      "```\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin! Reminder to always use the exact characters `Final Answer` when responding.\n"
     ]
    }
   ],
   "source": [
    "from inspect import signature\n",
    "\n",
    "tools_names = [tool.name for tool in tools]\n",
    "tools_descriptions = \"\\n\".join([f\"{tool.name}{signature(tool.func)} - {tool.description}\" for tool in tools]) \n",
    "\n",
    "# Taken from https://smith.langchain.com/hub/hwchase17/react-json\n",
    "instructions =f\"\"\"\"You are a reasoning and acting assistant. \\\n",
    "Answer the following questions as best you can. You have access to the following tools:\n",
    "\n",
    "{tools_descriptions}\n",
    "\n",
    "The way you use the tools is by specifying a json blob.\n",
    "Specifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\n",
    "\n",
    "The only values that should be in the \"action\" field are: {tools_names}\n",
    "\n",
    "The $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\n",
    "\n",
    "```\n",
    "{{\n",
    "  \"action\": $TOOL_NAME,\n",
    "  \"action_input\": $INPUT\n",
    "}}\n",
    "```\n",
    "\n",
    "ALWAYS use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action:\n",
    "```\n",
    "$JSON_BLOB\n",
    "```\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin! Reminder to always use the exact characters `Final Answer` when responding.\"\"\"\n",
    "\n",
    "print(instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be529b36",
   "metadata": {},
   "source": [
    "# Test the Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef58eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.Chatbot import Chatbot\n",
    "from langchain_core.messages import SystemMessage\n",
    "# Create a chat history with a system message and a human message\n",
    "chatbot = Chatbot(llm=llm, history=[SystemMessage(content=instructions)])\n",
    "chatbot.invoke(TEST_PROMPT0)\n",
    "# chatbot.interact()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cee0b09",
   "metadata": {},
   "source": [
    "<div style= \"padding: 0.5em;background-color: rgba(255,0,0, 0.5);width: 95%\">\n",
    "\n",
    "### **Problem: LLM Hallucinated the Tool Response**\n",
    "\n",
    "In this example, the LLM generated the keyword <em>\"Observation:\"</em> in its response, but we did not actually call the tool at that point. As a result, the LLM fabricated (hallucinated) a tool output instead of providing a real result from the tool.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459bfd24",
   "metadata": {},
   "source": [
    "# Interrupting the chatbot when generating '*Observations:*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8e7d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "binded_llm = llm.bind(stop=[\"Observation:\"])\n",
    "history = [SystemMessage(content=instructions)]\n",
    "chatbot = Chatbot(llm=binded_llm, history=history)\n",
    "chatbot.invoke(TEST_PROMPT0)\n",
    "#chatbot.interact()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a1b9e4",
   "metadata": {},
   "source": [
    "# Create an Agent Class\n",
    "\n",
    "<div style=\"background-color:rgba(0, 0, 0, 0); padding: 10px; border: 1px solid rgba(255, 255, 255, 1); border-radius: 5px; width: 95%; margin: 10px auto; text-align: center;\">\n",
    "\n",
    "### ðŸ“Š Workflow Diagram\n",
    "\n",
    "```mermaid\n",
    "flowchart LR\n",
    "   State0((START))\n",
    "   State1(ReAct Prompting)\n",
    "   State2(Assistant)\n",
    "   State4(Tools)\n",
    "   State3(Human)\n",
    "   State5((END))\n",
    "   State0 --> State1\n",
    "   State1 -- SystemMessage --> State2\n",
    "   State2 -- AiMessage --> State3\n",
    "   State2 -- AiMessage --> State4\n",
    "   State4 -- ToolMessage --> State2\n",
    "\n",
    "   State3 -- HumanMessage --> State2\n",
    "   State3 -- type `stop` --> State5\n",
    "```\n",
    "</div>\n",
    "\n",
    "\n",
    "The `Agent` class manages the core functionality of the chatbot and performs the following tasks:\n",
    "\n",
    "1. Halts LLM generation upon encountering the token `\"Observation:\"`.\n",
    "2. Parses the LLM output to extract the `action` and corresponding `action_input`.\n",
    "3. Executes the specified action and returns the observation.\n",
    "4. Proceed with the thought/action/observation cycle until `\"Final answer:\"` is produced.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea10267",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoload_ext autoreload\n",
    "%autoreload 2\n",
    "from src.Agent import Agent\n",
    "# Create an agent with the LLM and tools, and provide the instructions as a system message\n",
    "agent = Agent(llm=llm, tools=tools, history=[SystemMessage(content=instructions)])\n",
    "agent.invoke(TEST_PROMPT0)\n",
    "agent.invoke(TEST_PROMPT1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10822772",
   "metadata": {},
   "source": [
    "### To go further\n",
    "\n",
    "- ReAct limitations: the LLM must wait for the tool to finish before continuing its reasoning (it is slow).  \n",
    "  To overcome this limitation, you can use the [LLMCompiler](https://github.com/langchain-ai/langgraph/blob/main/docs/docs/tutorials/rewoo/rewoo.ipynb). The LLMCompiler allows the LLM to generate a plan of actions, which can then be executed in parallel. Once all actions are completed, the LLM can then process the results and provide a final response or trigger a another plan.\n",
    "  It has 3 main components:\n",
    "    - Planner: stream a [Directed Acyclic Graphs (DAGs)]{https://microsoft.github.io/promptflow/how-to-guides/develop-a-dag-flow/index.html} of function calls.\n",
    "    - Task Fetching Unit: schedules and executes the tasks as soon as they are executable\n",
    "    - Joiner: Responds to the user or triggers a second plan\n",
    "\n",
    "\n",
    " Explore Model Context Protocol (MCP) which allows you to make your tools and APIs publicly available to the LLMs.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
