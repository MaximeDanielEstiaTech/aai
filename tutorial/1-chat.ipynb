{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5661053",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(255, 0, 0, 0.5); padding: 10px; border-radius: 5px; width: 95%\">\n",
    "\n",
    "### üîí **Running a Large Language Model (LLM) locally**\n",
    "\n",
    "Large Language Models (LLMs) have become increasingly popular for various applications, including natural language processing, text generation, and more. However, they are hosted on cloud platforms, which can be costly and may raise privacy concerns. Running an LLM locally allows you to have more control over your data and potentially reduce costs.\n",
    "</div>\n",
    "\n",
    "<div style=\"background-color:rgba(0, 0, 0, 0.5); padding: 10px; border-radius: 5px; width: 95%\">\n",
    "\n",
    "### üöÄ **Purpose of This Notebook**\n",
    "\n",
    "This notebook demonstrates how to pull and serve a Large Language Model (LLM) locally using `Ollama` and to interact with it via  `LangChain` Python libary. \n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7537330f",
   "metadata": {},
   "source": [
    "# üöÄ Start Ollama Server\n",
    "\n",
    "Follow these steps to launch and prepare the Ollama server:\n",
    "\n",
    "1. **Open a terminal**  \n",
    "   ‚ò∞ ‚Üí *Terminal* ‚Üí *New Terminal*\n",
    "\n",
    "2. **Start the Ollama server** by running:\n",
    "\n",
    "   ```bash\n",
    "   ollama serve\n",
    "   ```\n",
    "\n",
    "3. **Do not close this terminal.**\n",
    "   Keep it running in the background.\n",
    "\n",
    "4. **Open another terminal**\n",
    "\n",
    "5. **Pull the model** `qwen3:4b` *(if not already done)*:\n",
    "\n",
    "   ```bash\n",
    "   ollama pull qwen3:4b\n",
    "   ```\n",
    "\n",
    "6. **Close this second terminal**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0485eea1",
   "metadata": {},
   "source": [
    "# üîí Define Global Constants\n",
    "\n",
    "Set up global constants to use throughout the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93995f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_BASE_URL = \"http://localhost:11434\"\n",
    "LLM_MODEL = \"qwen3:4b\"\n",
    "LLM_SEED = 42 \n",
    "LLM_TEMPERATURE = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eff3793",
   "metadata": {},
   "source": [
    "# ü§ñ Initialize Ollama Chatbot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267b6691",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# minimize randomness for reproducibility\n",
    "seed = 42\n",
    "temperature = 0\n",
    "\n",
    "# Set up the Ollama chat model with specified LLM model and parameters\n",
    "llm = ChatOllama(\n",
    "    base_url=OLLAMA_BASE_URL,\n",
    "    model=LLM_MODEL,\n",
    "    temperature=LLM_TEMPERATURE,\n",
    "    seed=LLM_SEED,\n",
    "    stream=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5cf451",
   "metadata": {},
   "source": [
    "# üí¨ Chat with the Assistant\n",
    "\n",
    "Follow the steps below to start and customize your conversation:\n",
    "\n",
    "1. **Run the cell** to start chatting with the assistant.  \n",
    "   ‚§∑ Type `stop` at any time to exit.\n",
    "\n",
    "2. **Customize the assistant's behavior** by editing the system instructions.  \n",
    "   Example:  \n",
    "   ```python\n",
    "   instructions = \"You are a mean assistant. Answer my questions in a mean way.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0eb4b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Initialize conversation history\n",
    "history = []\n",
    "# Display system instructions\n",
    "instructions = \"You are a helpful assistant. Answer my questions in a helpful way.\"\n",
    "system_message = SystemMessage(content=instructions)\n",
    "system_message.pretty_print()\n",
    "# Add system message to history\n",
    "history.append(system_message)\n",
    "\n",
    "while True: \n",
    "    # Get user input\n",
    "    prompt = input(\"Prompt (Enter 'stop' to exit)\")\n",
    "    if prompt == \"stop\": \n",
    "        break\n",
    "    # Display the prompt\n",
    "    human_message = HumanMessage(content=prompt)\n",
    "    human_message.pretty_print()\n",
    "    # Add human message to history\n",
    "    history.append(human_message)\n",
    "    # Prepare an AI message to hold the response\n",
    "    ai_message = AIMessage(content=\"\")\n",
    "    # Display the AI message header\n",
    "    ai_message.pretty_print()\n",
    "    print()\n",
    "    # Stream the response and update the AI message content\n",
    "    for chunk in llm.stream(history):\n",
    "        print(chunk.content, end=\"\")\n",
    "        ai_message.content += chunk.content\n",
    "    print()\n",
    "    # Add the AI message to history\n",
    "    history.append(ai_message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da17787",
   "metadata": {},
   "source": [
    "# üß± Chatbot Class\n",
    "\n",
    "To simplify usage, we've encapsulated the chatbot logic into a Python class.\n",
    "\n",
    "üìÅ See the implementation in: `src/chatbot.py`\n",
    "\n",
    "This class wraps the setup and interaction steps you‚Äôve seen earlier, making it easier to use the chatbot across multiple notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2598eb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.Chatbot import Chatbot\n",
    "# Create a Chatbot instance with the Ollama LLM\n",
    "chatbot = Chatbot(llm=llm, history=history)\n",
    "# Interact with the chatbot\n",
    "chatbot.interact()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682a72ee",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "üí° **Starting in the next Python notebooks**, we'll use this class to interact with the chatbot in a more structured and reusable way.\n",
    "\n",
    "\n",
    "If you are interested in chating with the assistant using user-friendly interface, you can use one of the following options:\n",
    "\n",
    "- [Msty](https://msty.app/)\n",
    "- [Open Web UI](https://docs.openwebui.com/)\n",
    "- [LM Studio](https://lmstudio.ai/)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
