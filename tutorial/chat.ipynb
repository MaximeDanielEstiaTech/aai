{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7537330f",
   "metadata": {},
   "source": [
    "# Start Ollama Server\n",
    "\n",
    "1. Open a terminal\n",
    "\n",
    "    â˜° > *Terminal* > *New Terminal*\n",
    "\n",
    "2. Start the Ollama server \n",
    "\n",
    "    ```bash\n",
    "    ollama serve\n",
    "    ```\n",
    "\n",
    "3. Do not close the terminal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0485eea1",
   "metadata": {},
   "source": [
    "# Define Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93995f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_BASE_URL = \"http://localhost:11434\"\n",
    "LLM_MODEL = \"qwen3:8b\"\n",
    "LLM_SEED = 42 \n",
    "LLM_TEMPERATURE = 0.0\n",
    "TEST_PROMPT0 = \"What time is it?\"\n",
    "TEST_PROMPT1 = \"What is the weather in Paris right now?\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eff3793",
   "metadata": {},
   "source": [
    "# Initialize Ollama Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "267b6691",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# minimize randomness for reproducibility\n",
    "seed = 42\n",
    "temperature = 0\n",
    "\n",
    "# Set up the Ollama chat model with specified LLM model and parameters\n",
    "llm = ChatOllama(\n",
    "    base_url=OLLAMA_BASE_URL,\n",
    "    model=LLM_MODEL,\n",
    "    temperature=LLM_TEMPERATURE,\n",
    "    seed=LLM_SEED,\n",
    "    stream=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5cf451",
   "metadata": {},
   "source": [
    "# Chat with it\n",
    "\n",
    "1. Run the cell to start a conversation with the chatbot. Type `stop` to exit at any time.\n",
    "2. Modify its behavior by changing the system instructions (e.g., \"You are a mean assistant. Answer my questions in a mean way.\").\n",
    "3. Interact with the chatbot again to observe the changes.\n",
    "4. If you discover something interesting or unexpected, feel free to share it with the person next to you or even the group!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c0eb4b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "You are a helpful assistant. Answer my questions in a helpful way.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "How are u?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "<think>\n",
      "Okay, the user asked \"How are u?\" which is a casual way of asking \"How are you?\" I need to respond in a friendly and helpful manner. Let me start by acknowledging their greeting. Since I'm an AI, I don't have feelings, but I should make sure to convey that I'm here to help. Maybe add a smiley to keep it light. Then, I should ask them how they're doing to show I care about their well-being. Keep the tone positive and open for conversation. Let me put that together.\n",
      "</think>\n",
      "\n",
      "Hi there! ðŸ˜Š I'm just a bunch of code and algorithms, so I don't have feelings, but I'm here and ready to help you with anything you need! How are you doing today? Let me know if there's something on your mind!\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Initialize conversation history\n",
    "history = []\n",
    "# Display system instructions\n",
    "instructions = \"You are a helpful assistant. Answer my questions in a helpful way.\"\n",
    "system_message = SystemMessage(content=instructions)\n",
    "system_message.pretty_print()\n",
    "# Add system message to history\n",
    "history.append(system_message)\n",
    "\n",
    "while True: \n",
    "    # Get user input\n",
    "    prompt = input(\"Prompt (Enter 'stop' to exit)\")\n",
    "    if prompt == \"stop\": \n",
    "        break\n",
    "    # Display the prompt\n",
    "    human_message = HumanMessage(content=prompt)\n",
    "    human_message.pretty_print()\n",
    "    # Add human message to history\n",
    "    history.append(human_message)\n",
    "    # Prepare an AI message to hold the response\n",
    "    ai_message = AIMessage(content=\"\")\n",
    "    # Display the AI message header\n",
    "    ai_message.pretty_print()\n",
    "    print()\n",
    "    # Stream the response and update the AI message content\n",
    "    for chunk in llm.stream(history):\n",
    "        print(chunk.content, end=\"\")\n",
    "        ai_message.content += chunk.content\n",
    "    print()\n",
    "    # Add the AI message to history\n",
    "    history.append(ai_message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0108ec",
   "metadata": {},
   "source": [
    "<div style=\"background-color:rgba(255, 0, 0, 0.5); padding: 10px; border-radius: 5px; width: 95%\">\n",
    "\n",
    "### **Limited autonomy of Large Language Models (LLMs)**\n",
    "\n",
    "Large Language Models (LLMs) do not have real-time awareness or access to current events. Their knowledge is based on static training data with a fixed cut-off date.\n",
    "They also cannot browse the web, run code, or interact with live tools unless explicitly connected to such systems.\n",
    "\n",
    "As a result, when asked questions that require up-to-date information or external actions, LLMs may:\n",
    "\n",
    "- Provide outdated, inaccurate, or nonsensical answers, **or**\n",
    "- Admit they donâ€™t know the answer.\n",
    "\n",
    "**Example:**  \n",
    "-  Ask the chatbot: _\"What time is it?\"_  \n",
    "- and observe how it responds.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf394cf",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
